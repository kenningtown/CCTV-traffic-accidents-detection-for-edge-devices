{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds the frame-level dataset TAD-YOLO-CLS/ from clips_index.json (one frame per clip), creates tad_cls.yaml, and fine-tunes YOLOv8n-cls on train/val; also runs the built-in Ultralytics test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60165,
     "status": "ok",
     "timestamp": 1763722171851,
     "user": {
      "displayName": "Khafiz Khader",
      "userId": "11904927306694258894"
     },
     "user_tz": -300
    },
    "id": "nkn_50UZ1VPA",
    "outputId": "1a86f0f7-c59f-42c3-bdd7-29cdc254eff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT exists: True\n",
      "SPLITS_PATH exists: True\n",
      "CLIPS_INDEX_PATH exists: True\n",
      "acc_train videos: 208\n",
      "norm_train videos: 88\n",
      "acc_val videos: 53\n",
      "norm_val videos: 23\n",
      "acc_test videos: 16\n",
      "norm_test videos: 16\n",
      "Total clips: 22037\n",
      "Sample clip: {'video_path': '/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/train/accident_1/videox3_10.mp4', 'frame_indices': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'label': 1, 'split': 'train'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "PROJECT_ROOT = \"/home/olzhas/programming/traffic-accident-edge\"\n",
    "DATA_ROOT = os.path.join(PROJECT_ROOT, \"TAD-benchmark\")\n",
    "\n",
    "SPLITS_PATH = os.path.join(DATA_ROOT, \"splits.json\")\n",
    "CLIPS_INDEX_PATH = os.path.join(DATA_ROOT, \"clips_index.json\")\n",
    "\n",
    "print(\"DATA_ROOT exists:\", os.path.exists(DATA_ROOT))\n",
    "print(\"SPLITS_PATH exists:\", os.path.exists(SPLITS_PATH))\n",
    "print(\"CLIPS_INDEX_PATH exists:\", os.path.exists(CLIPS_INDEX_PATH))\n",
    "\n",
    "with open(SPLITS_PATH, \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "with open(CLIPS_INDEX_PATH, \"r\") as f:\n",
    "    clips = json.load(f)\n",
    "\n",
    "print(\"acc_train videos:\", len(splits[\"acc_train\"]))\n",
    "print(\"norm_train videos:\", len(splits[\"norm_train\"]))\n",
    "print(\"acc_val videos:\", len(splits[\"acc_val\"]))\n",
    "print(\"norm_val videos:\", len(splits[\"norm_val\"]))\n",
    "print(\"acc_test videos:\", len(splits[\"acc_test\"]))\n",
    "print(\"norm_test videos:\", len(splits[\"norm_test\"]))\n",
    "print(\"Total clips:\", len(clips))\n",
    "print(\"Sample clip:\", clips[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO_DATA_ROOT: /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS\n",
      "/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/train/accident exists: True\n",
      "/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/train/normal exists: True\n",
      "/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val/accident exists: True\n",
      "/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val/normal exists: True\n",
      "/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/test/accident exists: True\n",
      "/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/test/normal exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "YOLO_DATA_ROOT = os.path.join(DATA_ROOT, \"TAD-YOLO-CLS\")\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in [\"accident\", \"normal\"]:\n",
    "        out_dir = os.path.join(YOLO_DATA_ROOT, split, cls)\n",
    "        if os.path.exists(out_dir):\n",
    "            shutil.rmtree(out_dir)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "print(\"YOLO_DATA_ROOT:\", YOLO_DATA_ROOT)\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in [\"accident\", \"normal\"]:\n",
    "        path = os.path.join(YOLO_DATA_ROOT, split, cls)\n",
    "        print(path, \"exists:\", os.path.exists(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frames: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22037/22037 [42:27<00:00,  8.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved images: 21983\n",
      "Failed extractions: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def save_frame(video_path, frame_idx, out_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ret or frame is None:\n",
    "        return False\n",
    "    cv2.imwrite(out_path, frame)\n",
    "    return True\n",
    "\n",
    "\n",
    "def label_to_name(label):\n",
    "    return \"accident\" if label == 1 else \"normal\"\n",
    "\n",
    "\n",
    "num_saved = 0\n",
    "num_failed = 0\n",
    "\n",
    "for clip in tqdm(clips, desc=\"Extracting frames\"):\n",
    "    video_path = clip[\"video_path\"]\n",
    "    frame_indices = clip[\"frame_indices\"]\n",
    "    label = clip[\"label\"]\n",
    "    split = clip[\"split\"]\n",
    "\n",
    "    center_idx = frame_indices[len(frame_indices) // 2]\n",
    "\n",
    "    cls_name = label_to_name(label)\n",
    "    video_base = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    out_name = f\"{video_base}_f{center_idx:05d}.jpg\"\n",
    "\n",
    "    out_dir = os.path.join(YOLO_DATA_ROOT, split, cls_name)\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        continue\n",
    "\n",
    "    ok = save_frame(video_path, center_idx, out_path)\n",
    "    if ok:\n",
    "        num_saved += 1\n",
    "    else:\n",
    "        num_failed += 1\n",
    "\n",
    "print(\"Saved images:\", num_saved)\n",
    "print(\"Failed extractions:\", num_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/accident: 12071 images\n",
      "train/normal: 3949 images\n",
      "val/accident: 2959 images\n",
      "val/normal: 944 images\n",
      "test/accident: 991 images\n",
      "test/normal: 1069 images\n",
      "\n",
      "Wrote YOLO config to: /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/tad_cls.yaml\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in [\"accident\", \"normal\"]:\n",
    "        pattern = os.path.join(YOLO_DATA_ROOT, split, cls, \"*.jpg\")\n",
    "        files = glob.glob(pattern)\n",
    "        print(f\"{split}/{cls}: {len(files)} images\")\n",
    "\n",
    "data_yaml = os.path.join(YOLO_DATA_ROOT, \"tad_cls.yaml\")\n",
    "\n",
    "with open(data_yaml, \"w\") as f:\n",
    "    f.write(f\"path: {YOLO_DATA_ROOT}\\n\")\n",
    "    f.write(\"train: train\\n\")\n",
    "    f.write(\"val: val\\n\")\n",
    "    f.write(\"test: test\\n\")\n",
    "    f.write(\"names:\\n\")\n",
    "    f.write(\"  0: accident\\n\")\n",
    "    f.write(\"  1: normal\\n\")\n",
    "\n",
    "print(\"\\nWrote YOLO config to:\", data_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "New https://pypi.org/project/ultralytics/8.3.230 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.229 ðŸš€ Python-3.13.9 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 10799MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/olzhas/Desktop/traffic-accident-edge/notebooks/runs/classify/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/train... found 16020 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val... found 3903 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/test... found 2003 images in 2 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 11.6MB/s 0.5s.4s<0.0s3s.0s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 508.9Â±82.6 MB/s, size: 322.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/train... 16020 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16020/16020 4.6Kit/s 3.5s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 231.9Â±75.1 MB/s, size: 68.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val... 3903 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3903/3903 3.8Kit/s 1.0s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/olzhas/Desktop/traffic-accident-edge/notebooks/runs/classify/train2\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/home/olzhas/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 543.4KB/s 1.4s 1.3s<0.2s\n",
      "\u001b[K       1/30     0.906G     0.2028         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.3it/s 47.6s<0.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 34.8it/s 0.9s0.1s\n",
      "                   all      0.945          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/30      1.04G    0.03816         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.5s<0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 40.7it/s 0.8s0.0s\n",
      "                   all      0.931          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/30      1.04G    0.05155         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.2it/s 47.8ss<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 44.1it/s 0.7s0.0s\n",
      "                   all      0.887          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/30      1.05G    0.03731         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.0it/s 50.1s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 31.8it/s 1.0s0.1s\n",
      "                   all       0.89          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/30      1.06G    0.03092         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.4it/s 46.3s0.2sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 45.8it/s 0.7s0.1s\n",
      "                   all      0.924          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/30      1.07G    0.02697         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.4it/s 46.8s<0.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 45.5it/s 0.7s0.1s\n",
      "                   all      0.912          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/30      1.07G    0.01698         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.4it/s 46.5s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 47.7it/s 0.6s0.2s\n",
      "                   all      0.934          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/30      1.08G    0.01465         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.4s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 48.9it/s 0.6s0.1s\n",
      "                   all      0.947          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/30      1.09G    0.01703         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 46.0s0.2sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 36.9it/s 0.8s0.1s\n",
      "                   all      0.925          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/30       1.1G    0.01535         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.4ss<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 47.1it/s 0.7s0.1s\n",
      "                   all      0.912          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/30      1.11G    0.02455         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.5s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 43.9it/s 0.7s0.0s\n",
      "                   all      0.926          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/30      1.12G    0.01466         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.3it/s 47.4ss<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 39.4it/s 0.8s0.0s\n",
      "                   all      0.919          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/30      1.12G    0.00808         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.3ss<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 47.2it/s 0.7s0.1s\n",
      "                   all      0.938          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/30      1.13G    0.01182         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.3it/s 47.6s<0.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 43.8it/s 0.7s0.0s\n",
      "                   all      0.932          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/30      1.14G    0.00542         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.4it/s 46.5s<0.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 35.2it/s 0.9s0.1s\n",
      "                   all      0.945          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/30      1.15G   0.009047         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.6it/s 44.8ss<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 44.2it/s 0.7s0.0s\n",
      "                   all      0.933          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/30      1.16G   0.004543         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.3it/s 47.8ss<0.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 44.2it/s 0.7s0.1s\n",
      "                   all      0.963          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/30      1.16G   0.007292         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.0it/s 50.4s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 52.6it/s 0.6s0.0s\n",
      "                   all      0.946          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/30      1.17G    0.01154         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.0it/s 50.3s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 48.1it/s 0.6s0.1s\n",
      "                   all      0.953          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/30      1.18G   0.004985         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.2it/s 48.4s<0.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 32.8it/s 0.9s0.2s\n",
      "                   all      0.934          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      21/30      1.19G   0.003881         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.6it/s 44.7s<0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 42.5it/s 0.7s0.0s\n",
      "                   all      0.948          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      22/30       1.2G   0.004573         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.6it/s 44.9s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 44.6it/s 0.7s0.0s\n",
      "                   all      0.921          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      23/30      1.21G   0.002106         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.6it/s 45.2s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 46.6it/s 0.7s0.1s\n",
      "                   all      0.922          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      24/30      1.21G   0.002856         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.7it/s 44.4ss<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 44.5it/s 0.7s0.0s\n",
      "                   all      0.947          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      25/30      1.22G    0.00126         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.6it/s 45.1s<0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 48.7it/s 0.6s0.1s\n",
      "                   all      0.941          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      26/30      1.23G   0.001155         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.6it/s 44.5s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 43.6it/s 0.7s0.1s\n",
      "                   all      0.941          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      27/30      1.24G   0.001739         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.7it/s 44.4ss<0.1s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 41.3it/s 0.8s0.1s\n",
      "                   all      0.943          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      28/30      1.25G   0.001171         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.4s<0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 50.9it/s 0.6s0.0s\n",
      "                   all      0.931          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      29/30      1.25G   0.001237         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.2s<0.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 41.5it/s 0.7s0.1s\n",
      "                   all      0.921          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      30/30      1.26G   0.001137         20        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 251/251 5.5it/s 45.5s<0.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 49.5it/s 0.6s0.1s\n",
      "                   all      0.927          1\n",
      "\n",
      "30 epochs completed in 0.395 hours.\n",
      "Optimizer stripped from /home/olzhas/Desktop/traffic-accident-edge/notebooks/runs/classify/train2/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from /home/olzhas/Desktop/traffic-accident-edge/notebooks/runs/classify/train2/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /home/olzhas/Desktop/traffic-accident-edge/notebooks/runs/classify/train2/weights/best.pt...\n",
      "Ultralytics 8.3.229 ðŸš€ Python-3.13.9 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 10799MiB)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/train... found 16020 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val... found 3903 images in 2 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/olzhas/Desktop/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/test... found 2003 images in 2 classes âœ… \n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 2.4it/s 13.2s<0.4s\n",
      "                   all      0.963          1\n",
      "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/olzhas/Desktop/traffic-accident-edge/notebooks/runs/classify/train2\u001b[0m\n",
      "Training finished. Results saved to: /home/olzhas/Desktop/traffic-accident-edge/notebooks/runs/classify/train2\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "model = YOLO(\"yolov8n-cls.pt\")\n",
    "\n",
    "results = model.train(\n",
    "    data=YOLO_DATA_ROOT,\n",
    "    epochs=30,\n",
    "    imgsz=224,\n",
    "    batch=64,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "print(\"Training finished. Results saved to:\", results.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights: /home/olzhas/programming/traffic-accident-edge/notebooks/runs/classify/train2/weights/best.pt\n",
      "Ultralytics 8.3.229 ðŸš€ Python-3.13.9 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 10799MiB)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2856.0Â±674.7 MB/s, size: 68.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val... 3903 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3903/3903 1.9Kit/s 2.1s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/val.cache\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 244/244 29.7it/s 8.2s0.1s\n",
      "                   all      0.963          1\n",
      "Speed: 0.1ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/olzhas/programming/traffic-accident-edge/notebooks/runs/classify/val2\u001b[0m\n",
      "VAL metrics: {'metrics/accuracy_top1': 0.9633615016937256, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9816807508468628}\n",
      "Ultralytics 8.3.229 ðŸš€ Python-3.13.9 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 10799MiB)\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5803.8Â±455.4 MB/s, size: 866.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/test... 2060 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2060/2060 1.8Kit/s 1.1s0.0s\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/TAD-YOLO-CLS/test.cache\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 129/129 15.3it/s 8.5s0.1s\n",
      "                   all      0.811          1\n",
      "Speed: 0.1ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/olzhas/programming/traffic-accident-edge/notebooks/runs/classify/val3\u001b[0m\n",
      "TEST metrics: {'metrics/accuracy_top1': 0.8106796145439148, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9053398072719574}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "best_weights = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"notebooks\",\n",
    "    \"runs\",\n",
    "    \"classify\",\n",
    "    \"train2\",\n",
    "    \"weights\",\n",
    "    \"best.pt\",\n",
    ")\n",
    "\n",
    "print(\"Using weights:\", best_weights)\n",
    "\n",
    "model = YOLO(best_weights)\n",
    "\n",
    "val_metrics = model.val(data=data_yaml, split=\"val\", device=0)\n",
    "print(\"VAL metrics:\", val_metrics.results_dict)\n",
    "\n",
    "test_metrics = model.val(data=data_yaml, split=\"test\", device=0)\n",
    "print(\"TEST metrics:\", test_metrics.results_dict)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOjN2aqKFPGyUR3Ozenfr2+",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
