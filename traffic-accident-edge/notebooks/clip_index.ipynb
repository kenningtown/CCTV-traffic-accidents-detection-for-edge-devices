{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads splits.json, computes video lengths, generates overlapping 16-frame clips (stride 8), and writes the central index clips_index.json with video_path, frame_indices, label, and split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3323,
     "status": "ok",
     "timestamp": 1763713065694,
     "user": {
      "displayName": "Khafiz Khader",
      "userId": "11904927306694258894"
     },
     "user_tz": -300
    },
    "id": "Qz3DyphCL1mP",
    "outputId": "9a356bc9-9327-4c79-baa0-8dd23c6e8aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed and saved splits.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = \"/home/olzhas/programming/traffic-accident-edge\"\n",
    "DATA_ROOT = os.path.join(PROJECT_ROOT, \"TAD-benchmark\")\n",
    "SPLITS_PATH = os.path.join(DATA_ROOT, \"splits.json\")\n",
    "\n",
    "with open(SPLITS_PATH, \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "old_prefixes = [\n",
    "    \"/content/drive/MyDrive/traffic-accident-edge\",\n",
    "    \"/home/olzhas/Desktop/traffic-accident-edge\",\n",
    "]\n",
    "\n",
    "\n",
    "def fix_path(p):\n",
    "    for old in old_prefixes:\n",
    "        if p.startswith(old):\n",
    "            return p.replace(old, PROJECT_ROOT)\n",
    "    if not os.path.isabs(p):\n",
    "        return os.path.join(DATA_ROOT, p)\n",
    "    return p\n",
    "\n",
    "\n",
    "for key in [\"acc_train\", \"acc_val\", \"norm_train\", \"norm_val\", \"acc_test\", \"norm_test\"]:\n",
    "    splits[key] = [fix_path(p) for p in splits[key]]\n",
    "\n",
    "with open(SPLITS_PATH, \"w\") as f:\n",
    "    json.dump(splits, f, indent=2)\n",
    "\n",
    "print(\"Fixed and saved splits.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example acc_train path: /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/train/accident_1/videox3_10.mp4\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "with open(SPLITS_PATH, \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "acc_train = splits[\"acc_train\"]\n",
    "norm_train = splits[\"norm_train\"]\n",
    "acc_val = splits[\"acc_val\"]\n",
    "norm_val = splits[\"norm_val\"]\n",
    "acc_test = splits[\"acc_test\"]\n",
    "norm_test = splits[\"norm_test\"]\n",
    "\n",
    "print(\"Example acc_train path:\", acc_train[0])\n",
    "print(\"Exists:\", os.path.exists(acc_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train: 208\n",
      "acc_val: 53\n",
      "norm_train: 88\n",
      "norm_val: 23\n",
      "acc_test: 16\n",
      "norm_test: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"acc_train:\", len(acc_train))\n",
    "print(\"acc_val:\", len(acc_val))\n",
    "\n",
    "print(\"norm_train:\", len(norm_train))\n",
    "print(\"norm_val:\", len(norm_val))\n",
    "\n",
    "print(\"acc_test:\", len(acc_test))\n",
    "print(\"norm_test:\", len(norm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8465,
     "status": "ok",
     "timestamp": 1763713077184,
     "user": {
      "displayName": "Khafiz Khader",
      "userId": "11904927306694258894"
     },
     "user_tz": -300
    },
    "id": "Wt-YTS8jd5ON",
    "outputId": "946fdb73-b3b7-4198-fcb8-cddf73dc6704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample accident video length info:\n",
      " frames: 799 fps: 25.0 seconds: 32.0\n",
      "\n",
      "Sample normal video length info:\n",
      " frames: 274 fps: 25.0 seconds: 11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "def video_length_info(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Could not open:\", video_path)\n",
    "        return 0, 0, 0.0\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps <= 0:\n",
    "        fps = 1\n",
    "    cap.release()\n",
    "    duration_sec = total_frames / fps\n",
    "    return total_frames, fps, duration_sec\n",
    "\n",
    "\n",
    "print(\"Sample accident video length info:\")\n",
    "f, fps, dur = video_length_info(acc_train[0])\n",
    "print(\" frames:\", f, \"fps:\", fps, \"seconds:\", round(dur, 1))\n",
    "\n",
    "print(\"\\nSample normal video length info:\")\n",
    "f, fps, dur = video_length_info(norm_train[0])\n",
    "print(\" frames:\", f, \"fps:\", fps, \"seconds:\", round(dur, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1763713582450,
     "user": {
      "displayName": "Khafiz Khader",
      "userId": "11904927306694258894"
     },
     "user_tz": -300
    },
    "id": "4UeHydothW5C",
    "outputId": "64bf7174-d6b8-49c2-cbae-cc89ba693603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample accident video: videox3_10.mp4\n",
      "  total clips: 98\n",
      "  first clip indices: [0, 1, 2, 3, 4] ... [11, 12, 13, 14, 15]\n",
      "Sample normal video: 20220518_acci-bg20.mp4\n",
      "  total clips: 33\n",
      "  first clip indices: [0, 1, 2, 3, 4] ... [11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "CLIP_LEN = 16\n",
    "STRIDE = 8\n",
    "MIN_FRAMES = 32\n",
    "\n",
    "\n",
    "def get_video_clips(video_path, clip_len=CLIP_LEN, stride=STRIDE, min_frames=MIN_FRAMES):\n",
    "    \"\"\"\n",
    "    For a given video, return a list of frame index lists.\n",
    "    Each element is something like [start, start+1, ..., start+clip_len-1].\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "\n",
    "    clips = []\n",
    "    if total < min_frames:\n",
    "        return clips\n",
    "\n",
    "    start = 0\n",
    "    while start + clip_len <= total:\n",
    "        frame_indices = list(range(start, start + clip_len))\n",
    "        clips.append(frame_indices)\n",
    "        start += stride\n",
    "\n",
    "    return clips\n",
    "\n",
    "\n",
    "acc_sample = acc_train[0]\n",
    "norm_sample = norm_train[0]\n",
    "\n",
    "acc_clips = get_video_clips(acc_sample)\n",
    "norm_clips = get_video_clips(norm_sample)\n",
    "\n",
    "print(\"Sample accident video:\", os.path.basename(acc_sample))\n",
    "print(\"  total clips:\", len(acc_clips))\n",
    "print(\"  first clip indices:\", acc_clips[0][:5], \"...\", acc_clips[0][-5:])\n",
    "\n",
    "print(\"Sample normal video:\", os.path.basename(norm_sample))\n",
    "print(\"  total clips:\", len(norm_clips))\n",
    "print(\"  first clip indices:\", norm_clips[0][:5], \"...\", norm_clips[0][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 475895,
     "status": "ok",
     "timestamp": 1763715257097,
     "user": {
      "displayName": "Khafiz Khader",
      "userId": "11904927306694258894"
     },
     "user_tz": -300
    },
    "id": "-mH_9dCzifMU",
    "outputId": "419749db-074e-4dd7-8605-3a7f65d73fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] processing video 1/208: videox3_10.mp4\n",
      "[train] processing video 11/208: videox13_1.mp4\n",
      "[train] processing video 21/208: video105.mp4\n",
      "[train] processing video 31/208: video36.mp4\n",
      "[train] processing video 41/208: video163.mp4\n",
      "[train] processing video 51/208: video85.mp4\n",
      "[train] processing video 61/208: video151.mp4\n",
      "[train] processing video 71/208: video102.mp4\n",
      "[train] processing video 81/208: videox14_3.mp4\n",
      "[train] processing video 91/208: video137.mp4\n",
      "[train] processing video 101/208: video141.mp4\n",
      "[train] processing video 111/208: video125_2.mp4\n",
      "[train] processing video 121/208: video168.mp4\n",
      "[train] processing video 131/208: videox8_1.mp4\n",
      "[train] processing video 141/208: video71.mp4\n",
      "[train] processing video 151/208: video45_2.mp4\n",
      "[train] processing video 161/208: video158.mp4\n",
      "[train] processing video 171/208: video82.mp4\n",
      "[train] processing video 181/208: video107.mp4\n",
      "[train] processing video 191/208: video16.mp4\n",
      "[train] processing video 201/208: video69.mp4\n",
      "[train] processing video 1/88: 20220518_acci-bg20.mp4\n",
      "[train] processing video 11/88: 20230818_acci-bg_19.mp4\n",
      "[train] processing video 21/88: 20230818_acci-bg_105.mp4\n",
      "[train] processing video 31/88: 20230818_acci-bg_83.mp4\n",
      "[train] processing video 41/88: 20220518_acci-bg42.mp4\n",
      "[train] processing video 51/88: 20230818_acci-bg_151.mp4\n",
      "[train] processing video 61/88: 20220620_acci-bg33.mp4\n",
      "[train] processing video 71/88: 20230818_acci-bg_17.mp4\n",
      "[train] processing video 81/88: 20230818_acci-bg_49.mp4\n",
      "[val] processing video 1/53: video193.mp4\n",
      "[val] processing video 11/53: video188.mp4\n",
      "[val] processing video 21/53: video20.mp4\n",
      "[val] processing video 31/53: video24.mp4\n",
      "[val] processing video 41/53: video52.mp4\n",
      "[val] processing video 51/53: videox24_1.mp4\n",
      "[val] processing video 1/23: 20220518_acci-bg38.mp4\n",
      "[val] processing video 11/23: 20220518_acci-bg24.mp4\n",
      "[val] processing video 21/23: 20220620_acci-bg37.mp4\n",
      "[test] processing video 1/16: v3.mov\n",
      "[test] processing video 11/16: v28.mov\n",
      "[test] processing video 1/16: videox_test_F3.mp4\n",
      "[test] processing video 11/16: videox_test_F15.mp4\n",
      "Total clips: 22037\n",
      "By split: Counter({'train': 16020, 'val': 3903, 'test': 2114})\n",
      "By label: Counter({1: 16075, 0: 5962})\n",
      "Sample entry: {'video_path': '/home/olzhas/programming/traffic-accident-edge/TAD-benchmark/train/accident_1/videox3_10.mp4', 'frame_indices': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'label': 1, 'split': 'train'}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def build_split_clips_debug(video_paths, label, split_name, max_videos=None):\n",
    "    \"\"\"\n",
    "    Same as before, but:\n",
    "    - can limit to first max_videos for testing\n",
    "    - prints progress every few videos\n",
    "    \"\"\"\n",
    "    all_samples = []\n",
    "    paths = video_paths if max_videos is None else video_paths[:max_videos]\n",
    "\n",
    "    for i, vp in enumerate(paths):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[{split_name}] processing video {i+1}/{len(paths)}:\",\n",
    "                  os.path.basename(vp))\n",
    "        clip_indices = get_video_clips(vp)\n",
    "        for idxs in clip_indices:\n",
    "            all_samples.append({\n",
    "                \"video_path\": vp,\n",
    "                \"frame_indices\": idxs,\n",
    "                \"label\": label,\n",
    "                \"split\": split_name,\n",
    "            })\n",
    "    return all_samples\n",
    "\n",
    "\n",
    "clips = []\n",
    "clips += build_split_clips_debug(acc_train, 1, \"train\")\n",
    "clips += build_split_clips_debug(norm_train, 0, \"train\")\n",
    "clips += build_split_clips_debug(acc_val,   1, \"val\")\n",
    "clips += build_split_clips_debug(norm_val,  0, \"val\")\n",
    "clips += build_split_clips_debug(acc_test,  1, \"test\")\n",
    "clips += build_split_clips_debug(norm_test, 0, \"test\")\n",
    "\n",
    "print(\"Total clips:\", len(clips))\n",
    "\n",
    "split_counts = Counter([c[\"split\"] for c in clips])\n",
    "label_counts = Counter([c[\"label\"] for c in clips])\n",
    "\n",
    "print(\"By split:\", split_counts)\n",
    "print(\"By label:\", label_counts)\n",
    "print(\"Sample entry:\", clips[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1763715371041,
     "user": {
      "displayName": "Khafiz Khader",
      "userId": "11904927306694258894"
     },
     "user_tz": -300
    },
    "id": "Mjieu4W_oMZ-",
    "outputId": "fa9f2ca8-031f-4054-8ea8-bac5033bb7a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 22037 clips to /home/olzhas/programming/traffic-accident-edge/TAD-benchmark/clips_index.json\n"
     ]
    }
   ],
   "source": [
    "CLIPS_INDEX_PATH = os.path.join(DATA_ROOT, \"clips_index.json\")\n",
    "\n",
    "with open(CLIPS_INDEX_PATH, \"w\") as f:\n",
    "    json.dump(clips, f, indent=2)\n",
    "\n",
    "print(\"Saved\", len(clips), \"clips to\", CLIPS_INDEX_PATH)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOVVnuYGw6UJ1GhpxsoaWUr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
